---
title: "Lab3"
output: html_document
date: "2022-11-26"
---

# Lab3

```{r}
TIN <- 20

set.seed(TIN)
```

## Part I: Markov Chain

### Problem 1

```{r}
TLN <- paste("0", TIN, sep = "")
```

Transition probabilities matrix:

$$
P=\begin{bmatrix}
0.9 & 0.1 & 0 & 0\\
0.8 & 0.1 & 0.1 & 0\\
0.9 & 0 & 0 & 0.1\\
0.8 & 0.1 & 0.1 & 0\\
\end{bmatrix}
$$

```{r}
P = matrix(c(
  0.9, 0.1, 0.0, 0.0,
  0.8, 0.1, 0.1, 0.0,
  0.9, 0.0, 0.0, 0.1,
  0.8, 0.1, 0.1, 0), nrow=4, byrow=T)

calculate_by_eigenvector <- function (probs) {
  left_eigenvector <- eigen(t(probs))$vectors[,1]
  return (sapply(left_eigenvector / sum(left_eigenvector), Re))
}

calculate_by_matrix_multiplication <- function (probs) {
  return ((probs %*% probs %*% probs %*% probs)[1, ])
}

cat("Limiting probabilities (eigenvectors): ", calculate_by_eigenvector(P), "\n")
cat("Limiting probabilities (matrices): ", calculate_by_matrix_multiplication(P))

```

```{r}
estimate_probability <- Vectorize(function (m, n) {
  sample_data <- apply(
    replicate(m, sample(0:9, n, replace = T)), 2,
    function(x) grepl(TLN, paste(x, collapse = "")))
  return (length(sample_data[sample_data == TRUE]) / length(sample_data))
})

theoretical_probability <- function (n) 1 - ((1 - 0.001) ^ n)
# 0.001 is the limiting probability of the state 4
```

```{r}
x <- seq(100, 2000, by = 100)
estimated_data = estimate_probability(500, x)
theoretical_data = theoretical_probability(x)
```

```{r}
plot(
  x,
  estimated_data, col ="blue", lwd = 3)
lines(
  x,
  theoretical_data)
```

Since $\bar{X}$ is our sample mean $M_n$ and $\mu$ is our theoretical mean, let $Z_n := \frac{\sqrt{n}}{\sigma}(M_n-\mu)$ be a random variable and, according to the Central Limit Theorem, it converges in law to the standard Gaussian random variable $Z \sim N(0,1)$ . Since we need to find a sample size $N$ which would guarantee that the absolute error of the estimate is below $0.03$ with confidence level of at least $95$ percent, we obtain the next equation:$$
P(|\bar{X}-\mu|\leq\varepsilon)=1-2\Phi(-\frac{\sqrt{n}}{\sigma}\varepsilon) \\
1-2\Phi(-\frac{\sqrt{n}}{\sigma}\varepsilon)=0.95 \\
\Phi(-\frac{\sqrt{n}}{\sigma}\varepsilon)=0.025 \\
\sqrt{n}=-\frac{\sigma\cdot z_{0.025}}{\varepsilon} \\
n=\sigma^2(\frac{z_{0.025}}{\varepsilon})^2 \\
n=p_n\cdot(1-p_n)\cdot(\frac{z_{0.025}}{0.03})^2 \\
n=(1-0.999^{1000})\cdot(0.999^{1000})\cdot(\frac{z_{0.025}}{0.03})^2 \\
n\sim992 
$$

```{r}
x <- seq(300, 800, by = 100)
n <- 1000
m <- 100
estimated_data = apply(replicate(m, estimate_probability(x, n) - theoretical_probability(n)), 1, function (x) quantile(x, .95))
plot(
  x,
  estimated_data, col ="blue", lwd = 3, type="l")
abline(h = 0.03, col = "darkgreen")
```

```{r}
N <- 1000
n <- 1000
m <- 100
hist(
  replicate(m, abs(estimate_probability(N, n) - theoretical_probability(n))),
  main = "Absolute error histogram",
  xlab = "Absolute error")
```

### Problem 2

Transition probabilities matrix:

$$
P=\begin{bmatrix}
0.9 & 0.1 & 0 & 0\\
0.8 & 0.1 & 0.1 & 0\\
0.9 & 0 & 0 & 0.1\\
0 & 0 & 0 & 1\\
\end{bmatrix}
$$

$$
\begin{cases}
\mu_1=1+0.9\cdot\mu_1+0.1\cdot\mu_2 \\
\mu_2=1+0.8\cdot\mu_1+0.1\cdot\mu_2+0.1\cdot\mu_3 \\
\mu_3=1+0.9\cdot\mu_1+0.1\cdot\mu_4 \\
\mu_4=0
\end{cases}
\Rightarrow
\begin{cases}
\mu_1=\frac{1+0.1\cdot\frac{1+0.8\cdot\mu_1+0.1\cdot(1+0.9\cdot\mu_1)}{0.9}}{0.1} \\
\mu_2=\frac{1+0.8\cdot\mu_1+0.1\cdot(1+0.9\cdot\mu_1)}{0.9} \\
\mu_3=1+0.9\cdot\mu_1 \\
\mu_4=0
\end{cases}
\\
\begin{cases}
\mu_1=10+\frac{10}{9}+\frac{8}{9}\mu_1+\frac{1}{9}+\frac{1}{10}\mu_1\Rightarrow\frac{90-80-9}{90}\mu_1=\frac{101}{9}\Rightarrow\mu_1=1010 \\
\mu_2=\frac{1+0.8\cdot\mu_1+0.1\cdot(1+0.9\cdot\mu_1)}{0.9}=\frac{10}{9}+\frac{8}{9}\mu_1+\frac{1}{9}+\frac{1}{10}\mu_1=\frac{11}{9}+\frac{89}{90}\mu_1=1000 \\
\mu_3=1+0.9\cdot\mu_1=1+909=910 \\
\mu_4=0
\end{cases}
$$

Hence, the estimated length is $\mu_1=1010$

```{r}
calculate_length <- Vectorize(function() {
  values <- vector()
  length <- 0
  while (paste(values, collapse = "") != TLN) {
    values <- tail(append(values, sample(0:9, 1)), nchar(TLN))
    length <- length + 1
  }
  return (length)
})

data <- replicate(100, calculate_length())
mean(data)
```

$$
P(|\hat{\theta}-\theta|<k\sigma)=1-
P(|\hat{\theta}-\theta|\geq k\sigma)\geq1-\frac{\sigma^2}{\sigma^2k^2}=1-\frac{1}{k^2} \\
1-\frac{1}{k^2}=0.95\Rightarrow k^2=20 \\
\sigma=\frac{\sigma_S}{\sqrt{n}} \\
k\sigma=10\Rightarrow\frac{\sigma_S}{\sqrt{n}}=\frac{10}{k}\Rightarrow n=\frac{\sigma_S^2\cdot k^2}{100}=\frac{\sigma_S^2}{5}
$$

```{r}
var(data) / 5
```

## Part II: Parameter estimation

### Problem 3

```{r}
theta <- TIN / 10
m <- 3000
x <- seq(100, 500, by=100)

estimate_method_1 <- function(data, alpha) {
  n <- length(data)
  lower = (2 * sum(data)) / (qchisq(df = 2 * n, p = 1 - alpha / 2))
  upper = (2 * sum(data)) / (qchisq(df = 2 * n, p = alpha / 2))
  return (c(lower, upper))
}

estimate_method_2 <- function(data, alpha) {
  n <- length(data)
  lower = mean(data) - (theta * qnorm(1 - alpha / 2)) / sqrt(n)
  upper = mean(data) + (theta * qnorm(1 - alpha / 2)) / sqrt(n)
  return (c(lower, upper))
}

estimate_method_3 <- function(data, alpha) {
  n <- length(data)
  lower = (mean(data) * sqrt(n)) / (qnorm(1 - alpha / 2) + sqrt(n))
  upper = (mean(data) * sqrt(n)) / (qnorm(alpha / 2) + sqrt(n))
  return (c(lower, upper))
}

estimate_method_4 <- function(data, alpha) {
  n <- length(data)
  lower = mean(data) - qt(1 - alpha / 2, n - 1) * sd(data) / sqrt(n)
  upper = mean(data) + qt(1 - alpha / 2, n - 1) * sd(data) / sqrt(n)
  return (c(lower, upper))
}

calculate_percentage <- function(n, alpha, method, generation_method) {
  func <- function (data) method(data, alpha)
  gen_method <- if (generation_method == "rexp") rexp else rpois
  mn <- if (generation_method == "rexp") 1 / theta else theta
  sample_data <- apply(matrix(gen_method(n * m, mn), nrow = m), 1, func)
  return (length(sample_data[,sample_data[1,] < theta & theta < sample_data[2,]]) / length(sample_data))
}

plot_method <- function(n, alpha, method, generation_method) {
  func <- Vectorize(function (n) calculate_percentage(n, alpha, method, generation_method))
  plot(
    x,
    func(x),
    type = "l",
    main = paste("Alpha is", alpha)
  )
}

plot_all <- function (method, generation_method) {
  plot_method(x, .1, method, generation_method)
  plot_method(x, .05, method, generation_method)
  plot_method(x, .01, method, generation_method)
}
```

#### Method 1

Let $Y_k=2\lambda X_k$. Hence $F_{Y_k}=P(Y_k\leq x)=P(2\lambda X_k\leq x)=P(X_k\leq\frac{x}{2\lambda})=F_{X_k}(\frac{x}{2\lambda})$

Taking the derivative on both sides:$f_{Y_{k}}( x) =\frac{1}{2\lambda } f_{X_{k}}( x) =\frac{1}{2\lambda } \lambda e^{-\lambda \frac{x}{2\lambda }} =\frac{1}{2} e^{-\frac{1}{2} x}$. Therefore, $Y_{k} \sim \mathcal{E}\left(\frac{1}{2}\right)$

Let's introduce statistics $T=2\lambda n\overline{X} =2\lambda \cdotp ( X_{1} +…+X_{n}) =Y_{1} +…+Y_{n}$.

Hence, $T\sim \Gamma \left( n,\ \frac{1}{2}\right) \sim \chi _{2n}^{2}$

Then, $P(\chi^{2n}_{\alpha/2}\leq2\lambda n\bar X\leq\chi^{2n}_{1-\alpha/2})=1-\alpha/2-\alpha/2=1-\alpha$.

$P(\chi^{2n}_{\alpha/2}\leq2\lambda n\bar X\leq\chi^{2n}_{1-\alpha/2})=P(\frac{\chi^{2n}_{\alpha/2}}{2\sum^n_{i=1}X_i}\leq\lambda \leq\frac{\chi^{2n}_{1-\alpha/2}}{2\sum^n_{i=1}X_i})=P(\frac{2\sum^n_{i=1}X_i}{\chi^{2n}_{1-\alpha/2}}\leq\theta \leq\frac{2\sum^n_{i=1}X_i}{\chi^{2n}_{\alpha/2}})=1-\alpha$

Therefore, $[\frac{2\sum^n_{i=1}X_i}{\chi^{2n}_{1-\alpha/2}},\frac{2\sum^n_{i=1}X_i}{\chi^{2n}_{\alpha/2}}]$ is $100(1-\alpha)$ confidence interval for $\theta$

```{r}
plot_all(estimate_method_1, "rexp")
```

```{r}
plot_all(estimate_method_2, "rexp")
```

```{r}
plot_all(estimate_method_3, "rexp")
```

#### Method 4

Let $T=(\bar X-\mu)\frac{\sqrt n}{S}\sim\mathcal{T}_{n-1}$ (as described in Ross textbook)

Hence, $P(t^{(n-1)}_{\alpha/2}\leq(\bar X-\mu)\frac{\sqrt n}{S}\leq t^{(n-1)}_{1-\alpha/2})=1-\alpha/2-\alpha/2=1-\alpha$.

$P(t^{(n-1)}_{\alpha/2}\leq(\bar X-\mu)\frac{\sqrt n}{S}\leq t^{(n-1)}_{1-\alpha/2})=P(-t^{(n-1)}_{\alpha/2}\frac{S}{\sqrt n}\geq\mu-\bar X\geq -t^{(n-1)}_{1-\alpha/2}\frac{S}{\sqrt n})=$

$=P(\bar X-t^{(n-1)}_{1-\alpha/2}\frac{S}{\sqrt n}\leq\mu\leq\bar X-t^{(n-1)}_{\alpha/2}\frac{S}{\sqrt n})=1-\alpha$

Thus, $[\bar X-t^{(n-1)}_{1-\alpha/2}\frac{S}{\sqrt n},\bar X+t^{(n-1)}_{1-\alpha/2}\frac{S}{\sqrt n}]$ is $100(1-\alpha)$ confidence interval for $\theta$

```{r}
plot_all(estimate_method_4, "rexp")
```

### Problem 4

```{r}
plot_all(estimate_method_2, "rpois")
```

```{r}
plot_all(estimate_method_3, "rpois")
```

```{r}
plot_all(estimate_method_4, "rpois")
```

#### Conclusion

As we can see all the methods give almost the same results
